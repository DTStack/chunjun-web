"use strict";(self.webpackChunkchunjun_web=self.webpackChunkchunjun_web||[]).push([[3457],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return d}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),d=a,h=p["".concat(s,".").concat(d)]||p[d]||m[d]||o;return n?r.createElement(h,i(i({ref:t},u),{},{components:n})):r.createElement(h,i({ref:t},u))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},2945:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return l},metadata:function(){return c},toc:function(){return m}});var r=n(7462),a=n(3366),o=(n(7294),n(3905)),i=["components"],l={},s="What is incremental mode",c={unversionedId:"chunjunDocs/incremental",id:"chunjunDocs/incremental",title:"What is incremental mode",description:"The incremental mode mainly applies to some Insert only tables. As the service grows,  a large amount of data is stored in the table. If the entire table is synchronized every time, it will consume more time and resources. Therefore, you need an incremental mode feature that reads only incremental portions of the data at a time.",source:"@site/docs/chunjunDocs/incremental.md",sourceDirName:"chunjunDocs",slug:"/chunjunDocs/incremental",permalink:"/chunjun-web/en/docs/chunjunDocs/incremental",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chunjunDocs/incremental.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"ChunJun generic configuration",permalink:"/chunjun-web/en/docs/chunjunDocs/general-configuration"}},u={},m=[{value:"Principle",id:"principle",level:2},{value:"Limit",id:"limit",level:2},{value:"How to handle increColumn repetition scenarios",id:"how-to-handle-increcolumn-repetition-scenarios",level:2},{value:"Environment prepare",id:"environment-prepare",level:2},{value:"json example",id:"json-example",level:2},{value:"Query in prometheus",id:"query-in-prometheus",level:2}],p={toc:m};function d(e){var t=e.components,l=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"what-is-incremental-mode"},"What is incremental mode"),(0,o.kt)("p",null,"The incremental mode mainly applies to some Insert only tables. As the service grows,  a large amount of data is stored in the table. If the entire table is synchronized every time, it will consume more time and resources. Therefore, you need an incremental mode feature that reads only incremental portions of the data at a time."),(0,o.kt)("h2",{id:"principle"},"Principle"),(0,o.kt)("p",null,"The incremental mode works by combining the increColumn with the filter criteria in the SQL statement of the query, such as where ID >? To filter out the data that has been read before."),(0,o.kt)("p",null,"Incremental mode is for two or more synchronous jobs. For jobs that perform incremental mode for the first time, which are actually full table synchronization,\nincremental mode differs from other jobs in that an endLocation metric is recorded after the job is executed and uploaded to Prometheus for subsequent use. Except for the first job, all subsequent incremental mode jobs take the endLocation of the previous job as the filter basis (startLocation) for this job.\nFor example, after the first job is executed and endLocation is 10, the next job will build SQL statements such as SELECT ID,name,age from table where ID > 10 to achieve incremental read."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"increColumn\uff1aIncrementally increasing a field in a database table, such as a self-increment ID")),(0,o.kt)("h2",{id:"limit"},"Limit"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Only RDB Reader plugins can be used",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"It is implemented by building SQL filtering statements and therefore can only be used with RDB plugins"),(0,o.kt)("li",{parentName:"ul"},"Incremental synchronization only cares about reads, not writes, and is therefore only relevant to reader plugins"))),(0,o.kt)("li",{parentName:"ul"},"Incremental fields can only be of numeric type and time type",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Indicators need to be uploaded to Prometheus, which does not support string types and therefore only supports data types and time types. The time type is converted to a timestamp and uploaded"))),(0,o.kt)("li",{parentName:"ul"},"The value of the increColumn can be repeated, but must be incremented",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Because of the use of '>', the field is required to be incremented.")))),(0,o.kt)("h2",{id:"how-to-handle-increcolumn-repetition-scenarios"},"How to handle increColumn repetition scenarios"),(0,o.kt)("p",null,"Consider a scenario in which the endLocation of an incremental mode is X, and data with the value of the delta key =x is written to the table in the interval between the start of the next incremental mode. By default, if the increment key is id, the next operation will concatenate such as SELECT ID,name,age FROM table WHERE ID > x. The data inserted in the gap with id=x will be lost.\nTo correspond to the above scenario, chunjun incremental mode provides the configuration item useMaxFunc (default is false). When setting useMaxFunc=true, Chunjun gets the maximum value of the increment key in the current database as the endLocation for the job when the increment job starts, and changes the operation symbol used for startLocation from '>' to '>='. Such as:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The SQL statement will be concatenated if the endLocation of the last job is 10 and the maximum ID is 100 when an increment is started ",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"SELECT id,name,age FROM table WHERE id >= 10 AND id < 100"))),(0,o.kt)("li",{parentName:"ul"},"When the next increment job starts with a maximum ID of 200, the SQL statement will be concatenated",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"SELECT id,name,age FROM table WHERE id >=100 AND id < 200")))),(0,o.kt)("h1",{id:"how-to-use-incremental-mode"},"How to use incremental mode"),(0,o.kt)("h2",{id:"environment-prepare"},"Environment prepare"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Because Prometheus is used to collect indicator information, Prometheus and PushGateway must be installed first.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Download the Flink Metric Prometheus dependency and place it in the Flink Lib directory"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://repo1.maven.org/maven2/org/apache/flink/flink-metrics-prometheus_2.12/1.12.7/flink-metrics-prometheus_2.12-1.12.7.jar"},"https://repo1.maven.org/maven2/org/apache/flink/flink-metrics-prometheus_2.12/1.12.7/flink-metrics-prometheus_2.12-1.12.7.jar")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Modify Flink configuration file conf/flink-conf.yaml to add Flink metric configuration"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"metrics.reporter.promgateway.host: host01\nmetrics.reporter.promgateway.port: 9091\nmetrics.reporter.promgateway.deleteOnShutdown: false\nmetrics.reporter.promgateway.class: org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter\n")))),(0,o.kt)("h2",{id:"json-example"},"json example"),(0,o.kt)("p",null,"The main configuration items are increColumn and startLocation"),(0,o.kt)("p",null,"Mysql is used as an example\uff1a"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "job": {\n    "content": [\n      {\n        "reader": {\n          "name": "mysqlreader",\n          "parameter": {\n            "column": [\n              {\n                "name": "id",\n                "type": "int"\n              },\n              {\n                "name": "name",\n                "type": "string"\n              },\n              {\n                "name": "age",\n                "type": "int"\n              }\n            ],\n            "customSql": "",\n            "increColumn": "id",  //Specify an increColumn for incremental mode. The increColumn must be a field that exists for column\n            "startLocation": "2", //Null for the first execution, configurable as a string or not, and subsequent submitted jobs use the values indicated in Prometheus\n            "username": "root",\n            "password": "root",\n            "connection": [\n              {\n                "jdbcUrl": [\n                  "jdbc:mysql://localhost:3306/test?useSSL=false"\n                ],\n                "table": [\n                  "baserow"\n                ]\n              }\n            ]\n          }\n        },\n        "writer": {\n          "name": "streamwriter",\n          "parameter": {\n            "print": false\n          }\n        }\n      }\n    ],\n    "setting": {\n      "restore": {\n        "restoreColumnName": "id"\n      },\n      "speed": {\n        "channel": 1,\n        "bytes": 0\n      }\n    }\n  }\n}\n\n')),(0,o.kt)("h2",{id:"query-in-prometheus"},"Query in prometheus"),(0,o.kt)("p",null,"Query the endLocation indicator value in Prometheus using the JobId corresponding to the Flink job"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'flink_taskmanager_job_task_operator_flinkx_endlocation{job_id="xxx"}\n')),(0,o.kt)("p",null,(0,o.kt)("img",{loading:"lazy",alt:"image-20220508231718458",src:n(2928).Z,width:"3154",height:"1790"})))}d.isMDXComponent=!0},2928:function(e,t,n){t.Z=n.p+"assets/images/prometheus-search-3fd9110d681059a8eee0540f189cff34.png"}}]);